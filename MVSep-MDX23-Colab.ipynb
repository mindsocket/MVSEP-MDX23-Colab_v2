{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy8kqE6DEFvm"
      },
      "source": [
        "# MVSep-MDX23 Colab Fork v2.3\n",
        "Adaptation of MVSep-MDX23 algorithm for Colab, with few tweaks:\n",
        "\n",
        "https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.3/MVSep-MDX23-Colab.ipynb\n",
        "\n",
        "Recent changes:\n",
        "<font size=2>\n",
        "\n",
        "**v2.3**\n",
        "* HQ3-Instr model replaced by VitLarge23 (thanks to MVSep)\n",
        "* Improved MDXv2 processing (thanks to Anjok)\n",
        "* Improved BigShifts algo (v2)\n",
        "* BigShifts processing added to MDXv3 & VitLarge\n",
        "* Faster folder batch processing\n",
        "\n",
        "</font>\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "    <summary>Full changelog :</summary>\n",
        "<br>\n",
        "<font size=2>\n",
        "<br>\n",
        "\n",
        "[**v2.2.2**](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/v2.2)\n",
        "* Improved MDXv3 chunking code (thanks to HymnStudio)\n",
        "* D1581 demo model replaced by new InstVocHQ MDXv3 model.\n",
        "<br>\n",
        "\n",
        "**v2.2.1**\n",
        "* Added custom weights feature\n",
        "* Fixed some bugs\n",
        "* Fixed input: you can use a file or a folder as input now\n",
        "<br>\n",
        "\n",
        "**v2.2**\n",
        "* Added MDXv3 compatibility\n",
        "* Added MDXv3 demo model D1581 in vocals stem multiband ensemble.\n",
        "* Added VOC-FT Fullband SRS instead of UVR-MDX-Instr-HQ3.\n",
        "* Added 2stems feature : output only vocals/instrum (faster processing)\n",
        "* Added 16bit output format option\n",
        "* Added \"BigShift trick\" for MDX models\n",
        "* Added separated overlap values for MDX, MDXv3 and Demucs\n",
        "* Fixed volume compensation fine-tuning for MDX-VOC-FT\n",
        "<br>\n",
        "\n",
        "[**v2.1 (by deton24)**](https://github.com/deton24/MVSEP-MDX23-Colab_v2.1)\n",
        "* Updated with MDX-VOC-FT instead of Kim Vocal 2\n",
        "<br>\n",
        "\n",
        "[**v2.0**](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/2.0)\n",
        "* Updated with new Kim Vocal 2 & UVR-MDX-Instr-HQ3 models\n",
        "* Folder batch processing\n",
        "* Fixed high frequency bleed in vocals\n",
        "* Fixed volume compensation for MDX models\n",
        "<br>\n",
        "</font>\n",
        "</details>\n",
        "<br>\n",
        "\n",
        "Credits:\n",
        "* [ZFTurbo/MVSep](https://github.com/ZFTurbo/MVSEP-MDX23-music-separation-model)\n",
        "* Models by [Demucs](https://github.com/facebookresearch/demucs), [Anjok](https://github.com/Anjok07/ultimatevocalremovergui) & [Kimberley Jensen](https://github.com/KimberleyJensen)\n",
        "* Adaptation & tweaks by [jarredou](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/)\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uWX5WOqjU0QC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0271a6-0cb4-4b4a-e0c5-28b1eb01b8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing... This will take 1 minute...\n",
            "/content\n",
            "Mounted at /content/drive\n",
            "/content/MVSEP-MDX23-Colab_v2\n",
            "Looking in indexes: https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/\n",
            "Collecting ort-nightly-gpu\n",
            "  Downloading https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/d3daa2b0-aa56-45ac-8145-2c3dc0661c87/pypi/download/ort-nightly-gpu/1.17.dev20231205004/ort_nightly_gpu-1.17.0.dev20231205004-cp310-cp310-manylinux_2_28_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from ort-nightly-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from ort-nightly-gpu) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from ort-nightly-gpu) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ort-nightly-gpu) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from ort-nightly-gpu) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from ort-nightly-gpu) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->ort-nightly-gpu) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->ort-nightly-gpu) (1.3.0)\n",
            "Installing collected packages: ort-nightly-gpu\n",
            "Successfully installed ort-nightly-gpu-1.17.0.dev20231205004\n",
            "Installation done !\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Installation\n",
        "#@markdown *Run this cell to install MVSep-MDX23*\n",
        "print('Installing... This will take 1 minute...')\n",
        "%cd /content\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/mindsocket/MVSEP-MDX23-Colab_v2.git &> /dev/null\n",
        "%cd /content/MVSEP-MDX23-Colab_v2\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "#!mkdir -p models\n",
        "#!cp -a /content/drive/MyDrive/dj_kanban/filesystem_copy/models/* models/\n",
        "# onnxruntime-gpu nightly fix for cuda12.2\n",
        "!python -m pip install ort-nightly-gpu --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/\n",
        "print('Installation done !')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x51nQyMEFvp"
      },
      "source": [
        "### About settings:\n",
        "\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **BigShifts :** Better quality/speed performance with values between 3 and 11, **BUT** 11 doesn't always give the best results. Think about it like seed, different values will give slightly different results.<br>\n",
        "Higher values = longer processing.\n",
        "</font>\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **Overlap InstVoc/VitLarge :** No big advantage to use high values when BigShifts is already high. If you use BigShifts=1 (regular processing), you can use higher values like 8 or even 16.<br>\n",
        "Higher values = longer processing.<br>\n",
        " *Same goes with overlap_VOCFT, but with values between 0 and 0.95*\n",
        "</font>\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **Weights :** How much importance the result from the given model will have in final results.\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7n1nXKsU4sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd46e9b-71b1-4c2a-c6e2-ddafd31baf63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MVSEP-MDX23-Colab_v2\n",
            "GPU use: 0\n",
            "started!\n",
            "\n",
            "Options: \n",
            "BigShifts: 7\n",
            "\n",
            "weight_InstVoc: 8.0\n",
            "weight_VitLarge: 5.0\n",
            "\n",
            "overlap_InstVoc: 1\n",
            "overlap_VitLarge: 1\n",
            "\n",
            "use_VOCFT: True\n",
            "overlap_VOCFT: 0.1\n",
            "weight_VOCFT: 2.0\n",
            "\n",
            "vocals_only: True\n",
            "output_format: PCM_16\n",
            "\n",
            "Loading InstVoc into memory\n",
            "Loading VitLarge into memory\n",
            "model.safetensors: 100% 850M/850M [00:03<00:00, 273MB/s]\n",
            "Loading VOCFT into memory\n",
            "100% 63.7M/63.7M [00:00<00:00, 353MB/s]\n",
            "Go for: /content/drive/MyDrive/dj_kanban/filesystem_copy/split_staging/01. Lily Allen - Smile.flac\n",
            "Input audio: (2, 8655360) Sample rate: 44100\n",
            "Processing vocals with VitLarge model...\n",
            "  0% 0/7 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "#@markdown #Separation\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "%cd /content/MVSEP-MDX23-Colab_v2\n",
        "\n",
        "\n",
        "input = '/content/drive/MyDrive/dj_kanban/filesystem_copy/split_staging' #@param {type:\"string\"}\n",
        "output_folder = '/content/drive/MyDrive/dj_kanban/filesystem_copy/mdx23' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown *Bigshifts=1 to disable that feature*\n",
        "\n",
        "BigShifts = 7 #@param {type:\"slider\", min:1, max:41, step:1}\n",
        "#@markdown ---\n",
        "overlap_InstVoc = 1 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "overlap_VitLarge = 1 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "#@markdown ---\n",
        "weight_InstVoc = 8 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "weight_VitLarge = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown ---\n",
        "use_VOCFT = True #@param {type:\"boolean\"}\n",
        "overlap_VOCFT = 0.1 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
        "weight_VOCFT = 2 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown ---\n",
        "vocals_instru_only = True #@param {type:\"boolean\"}\n",
        "overlap_demucs = 0.6 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
        "#@markdown ---\n",
        "output_format = 'PCM_16' #@param [\"PCM_16\", \"FLOAT\"]\n",
        "if vocals_instru_only:\n",
        "    vocals_only = '--vocals_only true'\n",
        "else:\n",
        "    vocals_only = ''\n",
        "\n",
        "\n",
        "if use_VOCFT:\n",
        "    use_VOCFT = '--use_VOCFT true'\n",
        "else:\n",
        "    use_VOCFT = ''\n",
        "\n",
        "if Path(input).is_file():\n",
        "  file_path = input\n",
        "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "  !python inference.py \\\n",
        "        --large_gpu \\\n",
        "        --weight_InstVoc {weight_InstVoc} \\\n",
        "        --weight_VOCFT {weight_VOCFT} \\\n",
        "        --weight_VitLarge {weight_VitLarge} \\\n",
        "        --input_audio \"{file_path}\" \\\n",
        "        --overlap_demucs {overlap_demucs} \\\n",
        "        --overlap_VOCFT {overlap_VOCFT} \\\n",
        "        --overlap_InstVoc {overlap_InstVoc} \\\n",
        "        --overlap_VitLarge {overlap_VitLarge} \\\n",
        "        --output_format {output_format} \\\n",
        "        --BigShifts {BigShifts} \\\n",
        "        --output_folder \"{output_folder}\" \\\n",
        "        {vocals_only} \\\n",
        "        {use_VOCFT}\n",
        "\n",
        "else:\n",
        "  file_paths = sorted(['\"' + path.replace(\"$\",\"\\\\$\") + '\"' for path in glob.glob(input + \"/*\") if not Path(output_folder + '/' + Path(path).stem + '_vocals.wav').exists()])[:]\n",
        "  input_audio_args = ' '.join(file_paths)\n",
        "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "  !python inference.py \\\n",
        "          --large_gpu \\\n",
        "          --weight_InstVoc {weight_InstVoc} \\\n",
        "          --weight_VOCFT {weight_VOCFT} \\\n",
        "          --weight_VitLarge {weight_VitLarge} \\\n",
        "          --input_audio {input_audio_args} \\\n",
        "          --overlap_demucs {overlap_demucs} \\\n",
        "          --overlap_VOCFT {overlap_VOCFT} \\\n",
        "          --overlap_InstVoc {int(overlap_InstVoc)} \\\n",
        "          --overlap_VitLarge {int(overlap_VitLarge)} \\\n",
        "          --output_format {output_format} \\\n",
        "          --BigShifts {BigShifts} \\\n",
        "          --output_folder \"{output_folder}\" \\\n",
        "          {vocals_only} \\\n",
        "          {use_VOCFT}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -a models/* /content/drive/MyDrive/dj_kanban/filesystem_copy/models/"
      ],
      "metadata": {
        "id": "K2s7z3YAIEPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: remove empty directories given a base path\n",
        "\n",
        "import os\n",
        "def remove_empty_dirs(base_path):\n",
        "    for dirpath, _, filenames in os.walk(base_path):\n",
        "        if not filenames and not dirpath == base_path:\n",
        "            #print(dirpath)\n",
        "            os.rmdir(dirpath)\n",
        "remove_empty_dirs(output_folder)"
      ],
      "metadata": {
        "id": "gl4tCbraIKLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "slKunkFfIkkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sorted(glob.glob(input+\"/*\"))[:])"
      ],
      "metadata": {
        "id": "5i3JRmsEIo9D",
        "outputId": "5628ae06-de16-47bb-ff11-c1793671d71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b34ad1ee7008>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --help"
      ],
      "metadata": {
        "id": "e_zNMXXNIuuV",
        "outputId": "cb62b7ac-9dc1-4ca9-cc22-131c4de1802d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU use: 0\n",
            "started!\n",
            "\n",
            "usage: inference.py [-h] --input_audio INPUT_AUDIO [INPUT_AUDIO ...] --output_folder OUTPUT_FOLDER\n",
            "                    [--cpu] [--overlap_demucs OVERLAP_DEMUCS] [--overlap_VOCFT OVERLAP_VOCFT]\n",
            "                    [--overlap_VitLarge OVERLAP_VITLARGE] [--overlap_InstVoc OVERLAP_INSTVOC]\n",
            "                    [--weight_InstVoc WEIGHT_INSTVOC] [--weight_VOCFT WEIGHT_VOCFT]\n",
            "                    [--weight_VitLarge WEIGHT_VITLARGE] [--single_onnx] [--large_gpu]\n",
            "                    [--BigShifts BIGSHIFTS] [--vocals_only VOCALS_ONLY] [--use_VOCFT USE_VOCFT]\n",
            "                    [--output_format OUTPUT_FORMAT]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --input_audio INPUT_AUDIO [INPUT_AUDIO ...], -i INPUT_AUDIO [INPUT_AUDIO ...]\n",
            "                        Input audio location. You can provide multiple files at once\n",
            "  --output_folder OUTPUT_FOLDER, -r OUTPUT_FOLDER\n",
            "                        Output audio folder\n",
            "  --cpu                 Choose CPU instead of GPU for processing. Can be very slow.\n",
            "  --overlap_demucs OVERLAP_DEMUCS\n",
            "                        Overlap of splited audio for light models. Closer to 1.0 - slower\n",
            "  --overlap_VOCFT OVERLAP_VOCFT\n",
            "                        Overlap of splited audio for heavy models. Closer to 1.0 - slower\n",
            "  --overlap_VitLarge OVERLAP_VITLARGE\n",
            "                        Overlap of splited audio for heavy models. Closer to 1.0 - slower\n",
            "  --overlap_InstVoc OVERLAP_INSTVOC\n",
            "                        MDXv3 overlap\n",
            "  --weight_InstVoc WEIGHT_INSTVOC\n",
            "                        Weight of MDXv3 model\n",
            "  --weight_VOCFT WEIGHT_VOCFT\n",
            "                        Weight of VOC-FT model\n",
            "  --weight_VitLarge WEIGHT_VITLARGE\n",
            "                        Weight of VitLarge model\n",
            "  --single_onnx         Only use single ONNX model for vocals. Can be useful if you have not\n",
            "                        enough GPU memory.\n",
            "  --large_gpu           It will store all models on GPU for faster processing of multiple audio\n",
            "                        files. Requires 11 and more GB of free GPU memory.\n",
            "  --BigShifts BIGSHIFTS\n",
            "                        Managing MDX 'BigShifts' trick value.\n",
            "  --vocals_only VOCALS_ONLY\n",
            "                        Vocals + instrumental only\n",
            "  --use_VOCFT USE_VOCFT\n",
            "                        use VOCFT in vocal ensemble\n",
            "  --output_format OUTPUT_FORMAT\n",
            "                        Output audio folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oexmXhyPIvPu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}